
# Version - 2
## Configurable crawler and chatbot based on crawled data
1. Configurable crawler - URL list, HTML tags,s3 name, and configurable AWS creds.
2. Move Postgres to Sqllite DB.
3. Create a vector DB based on the data in s3 DB.
4. Create a RAG Based pipeline and chatbot 


# Version - 1
# **Data Aggregator**

<span style="font-size: 22px;">
This enterprise-grade Java application is an automated data collection platform that empowers users to orchestrate scheduled data harvesting through a RESTful interface. Users can define target URLs and precise scheduling rules using cron expressions, giving them granular control over when and how data is collected. The system's core architecture includes a robust database for storing these configurations and a dynamic scheduler pool that manages concurrent data collection tasks, ensuring reliable execution at specified intervals. All harvested data is systematically stored in Amazon S3, building a comprehensive data lake suitable for advanced analytics and business intelligence dashboards. To maintain transparency and accountability, the system meticulously logs all execution activities and configuration changes, providing a complete audit history of data collection operations
<br>

# **Documentation**
Design</br>
![Screenshot 2024-10-22 at 7 16 04â€¯PM](https://github.com/user-attachments/assets/6b33980e-595d-4742-a4ae-991b2e7276f2)

<br><be>

# **License**

Distributed under the MIT License. See `LICENSE.txt` for more information.
<br><br>
